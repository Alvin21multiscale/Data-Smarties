{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Category</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307504</td>\n",
       "      <td>nyx sex bomb pallete natural palette</td>\n",
       "      <td>0</td>\n",
       "      <td>beauty_image/6b2e9cbb279ac95703348368aa65da09.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461203</td>\n",
       "      <td>etude house precious mineral any cushion pearl...</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/20450222d857c9571ba8fa23bdedc8c9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592295</td>\n",
       "      <td>milani rose powder blush</td>\n",
       "      <td>2</td>\n",
       "      <td>beauty_image/6a5962bed605a3dd6604ca3a4278a4f9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4460167</td>\n",
       "      <td>etude house baby sweet sugar powder</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/56987ae186e8a8e71fcc5a261ca485da.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5853995</td>\n",
       "      <td>bedak revlon color stay aqua mineral make up</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/9c6968066ebab57588c2f757a240d8b9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6208490</td>\n",
       "      <td>dr pure whitening cream</td>\n",
       "      <td>4</td>\n",
       "      <td>beauty_image/77e6b7e9d5544adbfda6809b2351c4fa.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6959546</td>\n",
       "      <td>chanel powder blush malice</td>\n",
       "      <td>2</td>\n",
       "      <td>beauty_image/485c4b8435a1e94976a569f3f014ea8b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8984461</td>\n",
       "      <td>snail white cream original 100</td>\n",
       "      <td>4</td>\n",
       "      <td>beauty_image/c7336f1c2e590d4c2bee219a6a0351a7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9184082</td>\n",
       "      <td>sunprise all proof spf 50</td>\n",
       "      <td>4</td>\n",
       "      <td>beauty_image/970b32aa659689f371516e5ceb423e25.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10345338</td>\n",
       "      <td>eyebrow powder nyx satuan rp 15.000 pc</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/49a47745248031775c98593f70f7201a.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid                                              title  Category  \\\n",
       "0    307504               nyx sex bomb pallete natural palette         0   \n",
       "1    461203  etude house precious mineral any cushion pearl...         1   \n",
       "2   3592295                           milani rose powder blush         2   \n",
       "3   4460167                etude house baby sweet sugar powder         3   \n",
       "4   5853995       bedak revlon color stay aqua mineral make up         3   \n",
       "5   6208490                            dr pure whitening cream         4   \n",
       "6   6959546                         chanel powder blush malice         2   \n",
       "7   8984461                     snail white cream original 100         4   \n",
       "8   9184082                          sunprise all proof spf 50         4   \n",
       "9  10345338             eyebrow powder nyx satuan rp 15.000 pc         3   \n",
       "\n",
       "                                          image_path  \n",
       "0  beauty_image/6b2e9cbb279ac95703348368aa65da09.jpg  \n",
       "1  beauty_image/20450222d857c9571ba8fa23bdedc8c9.jpg  \n",
       "2  beauty_image/6a5962bed605a3dd6604ca3a4278a4f9.jpg  \n",
       "3  beauty_image/56987ae186e8a8e71fcc5a261ca485da.jpg  \n",
       "4  beauty_image/9c6968066ebab57588c2f757a240d8b9.jpg  \n",
       "5  beauty_image/77e6b7e9d5544adbfda6809b2351c4fa.jpg  \n",
       "6  beauty_image/485c4b8435a1e94976a569f3f014ea8b.jpg  \n",
       "7  beauty_image/c7336f1c2e590d4c2bee219a6a0351a7.jpg  \n",
       "8  beauty_image/970b32aa659689f371516e5ceb423e25.jpg  \n",
       "9  beauty_image/49a47745248031775c98593f70f7201a.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('input/train.csv')\n",
    "# df = df[pd.notnull(df['tags'])]\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, TimeDistributed, Embedding\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posts, test_posts, train_tags, test_tags = train_test_split(df_train['title'], \n",
    "                                                                  df_train['Category'], \n",
    "                                                                  test_size=0.3, \n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_subset = pd.read_csv('input/subset_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 3000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(df_train_subset['title']) # only fit on suset training\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "max_words = 50\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n",
    "is_class0 = df_train['Category']==0\n",
    "class_0 = df_train[is_class0]\n",
    "\n",
    "\n",
    "tokenize.fit_on_texts(class_0['title']) # only fit on subset data\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    " \n",
    "for i in range(1,58):\n",
    "    print (i)\n",
    "    boolean_filter = df_train['Category']==i\n",
    "    class_i = df_train[boolean_filter]\n",
    "    \n",
    "    max_words = 50\n",
    "    tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "    \n",
    "    tokenize.fit_on_texts(class_i['title'])\n",
    "    x_train = np.append(x_train, tokenize.texts_to_matrix(train_posts), axis=1);\n",
    "    x_test = np.append(x_test, tokenize.texts_to_matrix(test_posts), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (466630, 2900)\n",
      "x_test shape: (199985, 2900)\n",
      "y_train shape: (466630, 58)\n",
      "y_test shape: (199985, 58)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etude house precious mineral any cushion pearl aura puff'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "input_length = x_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(LSTM(1500,input_shape=(1,input_length)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(512, activation='elu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(num_classes, activation='elu'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(num_classes, activation='elu'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "#output_dir = 'lstm_search'\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir=output_dir, histogram_freq=1, write_grads=True, write_graph= False, write_images=True)\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint(output_dir+'/best.h5', monitor='val_loss',save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 419967 samples, validate on 46663 samples\n",
      "Epoch 1/50\n",
      "419967/419967 [==============================] - 102s 242us/step - loss: 1.4248 - acc: 0.6071 - val_loss: 1.0668 - val_acc: 0.6764\n",
      "Epoch 2/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.2140 - acc: 0.6491 - val_loss: 1.0279 - val_acc: 0.6844\n",
      "Epoch 3/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.1732 - acc: 0.6588 - val_loss: 1.0067 - val_acc: 0.6884\n",
      "Epoch 4/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.1520 - acc: 0.6631 - val_loss: 1.0034 - val_acc: 0.6913\n",
      "Epoch 5/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.1338 - acc: 0.6675 - val_loss: 0.9888 - val_acc: 0.6957\n",
      "Epoch 6/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.1215 - acc: 0.6699 - val_loss: 0.9816 - val_acc: 0.6958\n",
      "Epoch 7/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.1084 - acc: 0.6733 - val_loss: 0.9772 - val_acc: 0.6981\n",
      "Epoch 8/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0977 - acc: 0.6762 - val_loss: 0.9732 - val_acc: 0.6985\n",
      "Epoch 9/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0880 - acc: 0.6789 - val_loss: 0.9684 - val_acc: 0.7002\n",
      "Epoch 10/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0780 - acc: 0.6811 - val_loss: 0.9624 - val_acc: 0.7019\n",
      "Epoch 11/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0711 - acc: 0.6835 - val_loss: 0.9614 - val_acc: 0.7031\n",
      "Epoch 12/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0621 - acc: 0.6850 - val_loss: 0.9557 - val_acc: 0.7032\n",
      "Epoch 13/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0540 - acc: 0.6869 - val_loss: 0.9543 - val_acc: 0.7036\n",
      "Epoch 14/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0486 - acc: 0.6883 - val_loss: 0.9535 - val_acc: 0.7036\n",
      "Epoch 15/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0417 - acc: 0.6905 - val_loss: 0.9561 - val_acc: 0.7046\n",
      "Epoch 16/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0349 - acc: 0.6921 - val_loss: 0.9532 - val_acc: 0.7070\n",
      "Epoch 17/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0283 - acc: 0.6946 - val_loss: 0.9516 - val_acc: 0.7071\n",
      "Epoch 18/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0243 - acc: 0.6956 - val_loss: 0.9563 - val_acc: 0.7061\n",
      "Epoch 19/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0160 - acc: 0.6971 - val_loss: 0.9469 - val_acc: 0.7092\n",
      "Epoch 20/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0116 - acc: 0.6983 - val_loss: 0.9493 - val_acc: 0.7102\n",
      "Epoch 21/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0051 - acc: 0.6999 - val_loss: 0.9451 - val_acc: 0.7089\n",
      "Epoch 22/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 1.0003 - acc: 0.7022 - val_loss: 0.9542 - val_acc: 0.7098\n",
      "Epoch 23/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9934 - acc: 0.7027 - val_loss: 0.9461 - val_acc: 0.7098\n",
      "Epoch 24/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9899 - acc: 0.7045 - val_loss: 0.9468 - val_acc: 0.7111\n",
      "Epoch 25/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9839 - acc: 0.7057 - val_loss: 0.9464 - val_acc: 0.7115\n",
      "Epoch 26/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9794 - acc: 0.7071 - val_loss: 0.9527 - val_acc: 0.7114\n",
      "Epoch 27/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9749 - acc: 0.7086 - val_loss: 0.9503 - val_acc: 0.7103\n",
      "Epoch 28/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9697 - acc: 0.7096 - val_loss: 0.9514 - val_acc: 0.7112\n",
      "Epoch 29/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9662 - acc: 0.7106 - val_loss: 0.9518 - val_acc: 0.7097\n",
      "Epoch 30/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9609 - acc: 0.7126 - val_loss: 0.9576 - val_acc: 0.7115\n",
      "Epoch 31/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9546 - acc: 0.7139 - val_loss: 0.9557 - val_acc: 0.7122\n",
      "Epoch 32/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9524 - acc: 0.7144 - val_loss: 0.9592 - val_acc: 0.7126\n",
      "Epoch 33/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9492 - acc: 0.7151 - val_loss: 0.9609 - val_acc: 0.7119\n",
      "Epoch 34/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9445 - acc: 0.7168 - val_loss: 0.9558 - val_acc: 0.7115\n",
      "Epoch 35/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9400 - acc: 0.7180 - val_loss: 0.9536 - val_acc: 0.7120\n",
      "Epoch 36/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9364 - acc: 0.7191 - val_loss: 0.9559 - val_acc: 0.7131\n",
      "Epoch 37/50\n",
      "419967/419967 [==============================] - 93s 221us/step - loss: 0.9317 - acc: 0.7202 - val_loss: 0.9566 - val_acc: 0.7132\n",
      "Epoch 38/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9275 - acc: 0.7216 - val_loss: 0.9591 - val_acc: 0.7126\n",
      "Epoch 39/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9257 - acc: 0.7223 - val_loss: 0.9623 - val_acc: 0.7126\n",
      "Epoch 40/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9224 - acc: 0.7224 - val_loss: 0.9601 - val_acc: 0.7139\n",
      "Epoch 41/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9170 - acc: 0.7248 - val_loss: 0.9593 - val_acc: 0.7143\n",
      "Epoch 42/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9126 - acc: 0.7263 - val_loss: 0.9638 - val_acc: 0.7130\n",
      "Epoch 43/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9104 - acc: 0.7266 - val_loss: 0.9585 - val_acc: 0.7139\n",
      "Epoch 44/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9060 - acc: 0.7278 - val_loss: 0.9576 - val_acc: 0.7153\n",
      "Epoch 45/50\n",
      "419967/419967 [==============================] - 93s 222us/step - loss: 0.9041 - acc: 0.7286 - val_loss: 0.9648 - val_acc: 0.7154\n",
      "Epoch 46/50\n",
      "419967/419967 [==============================] - 93s 223us/step - loss: 0.9004 - acc: 0.7290 - val_loss: 0.9634 - val_acc: 0.7144\n",
      "Epoch 47/50\n",
      "371968/419967 [=========================>....] - ETA: 10s - loss: 0.8947 - acc: 0.7302"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train.reshape((x_train.shape[0],1,x_train.shape[1])), y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199985/199985 [==============================] - 11s 57us/step\n",
      "Test accuracy: 0.7105932944881459\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test.reshape((x_test.shape[0],1,x_test.shape[1])), y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199985/199985 [==============================] - 44s 218us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_predicted = model.predict_classes(x_test.reshape((x_test.shape[0],1,x_test.shape[1])), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_num = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47      1108\n",
      "           1       0.80      0.57      0.67      8587\n",
      "           2       0.81      0.85      0.83      3446\n",
      "           3       0.86      0.86      0.86     24217\n",
      "           4       0.64      0.77      0.70     12714\n",
      "           5       0.74      0.79      0.76     16764\n",
      "           6       0.37      0.41      0.39       618\n",
      "           7       0.77      0.71      0.74      3538\n",
      "           8       0.57      0.64      0.61      1836\n",
      "           9       0.77      0.41      0.53      2409\n",
      "          10       0.70      0.54      0.61       321\n",
      "          11       0.55      0.54      0.54      1204\n",
      "          12       0.72      0.92      0.81      6535\n",
      "          13       0.70      0.53      0.60       942\n",
      "          14       0.45      0.04      0.08       766\n",
      "          15       0.62      0.04      0.08       182\n",
      "          16       0.93      0.02      0.04       668\n",
      "          17       0.83      0.04      0.07       814\n",
      "          18       0.52      0.80      0.63     17088\n",
      "          19       0.59      0.57      0.58      3977\n",
      "          20       0.62      0.37      0.47      6075\n",
      "          21       0.57      0.01      0.01      3226\n",
      "          22       0.54      0.26      0.35      4481\n",
      "          23       0.64      0.68      0.66       507\n",
      "          24       0.50      0.10      0.17      1230\n",
      "          25       0.74      0.77      0.75     10188\n",
      "          26       0.60      0.72      0.65     10131\n",
      "          27       0.72      0.50      0.59      4842\n",
      "          28       0.61      0.61      0.61      1962\n",
      "          29       0.59      0.61      0.60      1003\n",
      "          30       0.20      0.00      0.01       441\n",
      "          31       0.83      0.88      0.85      8285\n",
      "          32       0.82      0.91      0.86      8936\n",
      "          33       0.82      0.95      0.88      1465\n",
      "          34       0.77      0.82      0.79      4439\n",
      "          35       0.66      0.41      0.50      9220\n",
      "          36       0.79      0.90      0.84       284\n",
      "          37       0.77      0.84      0.80       659\n",
      "          38       0.80      0.95      0.87      1431\n",
      "          39       0.84      0.87      0.86       227\n",
      "          40       0.67      0.17      0.27        95\n",
      "          41       0.83      0.92      0.88      5749\n",
      "          42       0.82      0.93      0.87      3186\n",
      "          43       0.73      0.91      0.81      1824\n",
      "          44       0.90      0.83      0.86       303\n",
      "          45       0.86      0.89      0.87       714\n",
      "          46       0.88      0.93      0.90       206\n",
      "          47       0.78      0.74      0.76       308\n",
      "          48       0.78      0.90      0.83       107\n",
      "          49       0.66      0.37      0.47       173\n",
      "          50       0.79      0.90      0.84        69\n",
      "          51       0.69      0.87      0.77       128\n",
      "          52       0.76      0.38      0.51        34\n",
      "          53       0.80      0.47      0.59       117\n",
      "          54       0.78      0.71      0.74        96\n",
      "          55       0.79      0.69      0.73        48\n",
      "          56       0.69      0.42      0.52        48\n",
      "          57       0.00      0.00      0.00        14\n",
      "\n",
      "   micro avg       0.71      0.71      0.71    199985\n",
      "   macro avg       0.69      0.60      0.60    199985\n",
      "weighted avg       0.71      0.71      0.69    199985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_num, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>flormar 7 white cream bb spf 30 40ml</td>\n",
       "      <td>beauty_image/1588591395c5a254bab84042005f2a9f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>maybelline clear smooth all in one bb cream sp...</td>\n",
       "      <td>beauty_image/920985ed9587ea20f58686ea74e20f93.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>murah innisfree eco natural green tea bb cream...</td>\n",
       "      <td>beauty_image/90b40e5710f54352b243fcfb0f5d1d7f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>loreal white perfect day cream spf 17 pa white...</td>\n",
       "      <td>beauty_image/289c668ef3d70e1d929d602d52d5d78a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>hada labo cc cream ultimate anti aging spf 35 ...</td>\n",
       "      <td>beauty_image/d5b3e652c5822d2306f4560488ec30c6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1327710392</td>\n",
       "      <td>cathy doll cc speed white powder pact spf 40 o...</td>\n",
       "      <td>beauty_image/e1e50828d5594721a7d5d5c1ff78afbd.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1328802799</td>\n",
       "      <td>safi white natural brightening cream 45g</td>\n",
       "      <td>beauty_image/97ec852d5afc5d82ac02b80083cf292f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1330468145</td>\n",
       "      <td>light beige 03 bioaqua bb cushion exquisite de...</td>\n",
       "      <td>beauty_image/8ce1a5fe546f0cc795329bad599a8d5a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1677309730</td>\n",
       "      <td>new produk missha m perfect bb cream share in ...</td>\n",
       "      <td>beauty_image/755fcc85c687e8cb53d2a8d43ebfe251.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1683142205</td>\n",
       "      <td>ready laneige bb cushion anti aging spf 50 pa</td>\n",
       "      <td>beauty_image/34b56398c099505c650cf2447dc9f21f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid                                              title  \\\n",
       "0   370855998               flormar 7 white cream bb spf 30 40ml   \n",
       "1   637234604  maybelline clear smooth all in one bb cream sp...   \n",
       "2   690282890  murah innisfree eco natural green tea bb cream...   \n",
       "3   930913462  loreal white perfect day cream spf 17 pa white...   \n",
       "4  1039280071  hada labo cc cream ultimate anti aging spf 35 ...   \n",
       "5  1327710392  cathy doll cc speed white powder pact spf 40 o...   \n",
       "6  1328802799           safi white natural brightening cream 45g   \n",
       "7  1330468145  light beige 03 bioaqua bb cushion exquisite de...   \n",
       "8  1677309730  new produk missha m perfect bb cream share in ...   \n",
       "9  1683142205      ready laneige bb cushion anti aging spf 50 pa   \n",
       "\n",
       "                                          image_path  \n",
       "0  beauty_image/1588591395c5a254bab84042005f2a9f.jpg  \n",
       "1  beauty_image/920985ed9587ea20f58686ea74e20f93.jpg  \n",
       "2  beauty_image/90b40e5710f54352b243fcfb0f5d1d7f.jpg  \n",
       "3  beauty_image/289c668ef3d70e1d929d602d52d5d78a.jpg  \n",
       "4  beauty_image/d5b3e652c5822d2306f4560488ec30c6.jpg  \n",
       "5  beauty_image/e1e50828d5594721a7d5d5c1ff78afbd.jpg  \n",
       "6  beauty_image/97ec852d5afc5d82ac02b80083cf292f.jpg  \n",
       "7  beauty_image/8ce1a5fe546f0cc795329bad599a8d5a.jpg  \n",
       "8  beauty_image/755fcc85c687e8cb53d2a8d43ebfe251.jpg  \n",
       "9  beauty_image/34b56398c099505c650cf2447dc9f21f.jpg  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_public = pd.read_csv('input/test.csv')\n",
    "df_public.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_public = tokenize.texts_to_matrix(df_public[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172402/172402 [==============================] - 32s 186us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_public.reshape((x_public.shape[0],1,x_public.shape[1])), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public['Category'] = [np.argmax(pred) for pred in preds]\n",
    "df_submit = df_public[['itemid', 'Category']].copy()\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Mar23_3pm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
